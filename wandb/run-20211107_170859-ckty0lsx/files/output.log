model sim and label tuples:
0.48424482345581055 1.0
0.48425185680389404 1.0
0.48425477743148804 0.0
0.48424649238586426 1.0
0.48428037762641907 0.0
0.4843039810657501 1.0
0.48425689339637756 1.0
0.4842572510242462 1.0
0.4842568039894104 0.0
0.48424917459487915 0.0
0.4842536151409149 0.0
0.4842848479747772 1.0
0.48423710465431213 0.0
0.4842775762081146 0.0
0.48426327109336853 0.0
0.4842640459537506 1.0
0.484261155128479 1.0
0.48427340388298035 1.0
0.4842779338359833 1.0
0.48425376415252686 1.0
0.4842621684074402 1.0
0.4842570126056671 1.0
0.4842413067817688 1.0
0.4842856526374817 0.0
0.48426753282546997 1.0
0.4842432737350464 1.0
0.48425057530403137 1.0
0.4842648506164551 0.0
0.48426350951194763 0.0
0.48427608609199524 0.0
0.4842725694179535 1.0
0.48426148295402527 0.0
0.4842497408390045 0.0
0.4842563569545746 0.0
0.48427367210388184 0.0
0.4842258095741272 1.0
0.4842883348464966 1.0
0.48425254225730896 1.0
0.4842405319213867 0.0
0.4842573404312134 1.0
0.48426350951194763 1.0
0.484304815530777 1.0
0.48424482345581055 0.0
0.4842524230480194 0.0
0.4842775762081146 1.0
0.48425590991973877 0.0
0.4842453896999359 1.0
0.48425745964050293 0.0
0.4842360019683838 0.0
0.4842839241027832 0.0
0.48425018787384033 1.0
0.4842524230480194 1.0
0.48427876830101013 1.0
0.4842323064804077 1.0
0.4842543303966522 0.0
0.48425590991973877 1.0
0.484241247177124 0.0
0.48425859212875366 1.0
0.4842630624771118 1.0
0.4842473864555359 0.0
0.48427245020866394 0.0
0.4842473864555359 0.0
0.48426204919815063 0.0
0.4842635691165924 0.0
TRAIN[steps=100] loss=0.695609 acc=0.469 P=0.000 R=0.000 F1=0.000000
DEV[steps=100] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48007601499557495 0.0
0.48008450865745544 1.0
0.48006269335746765 1.0
0.4800528585910797 0.0
0.480042964220047 0.0
0.4800547957420349 1.0
0.4800716042518616 1.0
0.48003488779067993 0.0
0.4800480902194977 1.0
0.4800639748573303 1.0
0.480056494474411 1.0
0.4800531566143036 1.0
0.4800380766391754 1.0
0.48007115721702576 0.0
0.480049729347229 0.0
0.48012953996658325 1.0
0.48006027936935425 1.0
0.4800906777381897 0.0
0.4800238013267517 0.0
0.48007258772850037 0.0
0.48007532954216003 0.0
0.48006731271743774 1.0
0.48006853461265564 0.0
0.4800712764263153 1.0
0.48007237911224365 1.0
0.4800758957862854 0.0
0.4800738990306854 0.0
0.4800679683685303 0.0
0.48006346821784973 1.0
0.4800834655761719 1.0
0.4800495207309723 1.0
0.4800352454185486 1.0
0.4800679683685303 1.0
0.48006847500801086 0.0
0.48006898164749146 1.0
0.480085551738739 1.0
0.4800647497177124 0.0
0.4800468683242798 0.0
0.48007962107658386 0.0
0.48011118173599243 0.0
0.48004835844039917 0.0
0.4800701141357422 0.0
0.4800352454185486 0.0
0.480049729347229 1.0
0.48006847500801086 0.0
0.48006659746170044 0.0
0.48007237911224365 0.0
0.4800467789173126 1.0
0.48004788160324097 1.0
0.48004764318466187 1.0
0.4800587594509125 1.0
0.480074405670166 1.0
0.48002925515174866 1.0
0.48005610704421997 0.0
0.4800548553466797 0.0
0.4800642430782318 0.0
0.48005422949790955 0.0
0.48006829619407654 1.0
0.4800674319267273 1.0
0.48005950450897217 1.0
0.48007282614707947 0.0
0.48004797101020813 1.0
0.4800455570220947 0.0
0.48007604479789734 0.0
TRAIN[steps=200] loss=0.693944 acc=0.500 P=0.000 R=0.000 F1=0.000000
DEV[steps=200] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4816271662712097 1.0
0.4816187918186188 0.0
0.4816453456878662 1.0
0.4816448390483856 0.0
0.4816840589046478 1.0
0.48163744807243347 1.0
0.4816262722015381 1.0
0.48162680864334106 0.0
0.48162975907325745 1.0
0.481635183095932 1.0
0.4816198945045471 1.0
0.48162251710891724 0.0
0.4816409647464752 0.0
0.48163965344429016 0.0
0.4816398620605469 0.0
0.4816323518753052 0.0
0.4816703498363495 1.0
0.48165103793144226 1.0
0.48163023591041565 0.0
0.4816475510597229 0.0
0.48164209723472595 1.0
0.48164132237434387 0.0
0.481638103723526 0.0
0.48163479566574097 1.0
0.48163655400276184 0.0
0.4816295802593231 0.0
0.4816342294216156 1.0
0.48163506388664246 1.0
0.4816272556781769 1.0
0.4816191792488098 0.0
0.48160725831985474 0.0
0.48161908984184265 0.0
0.4816301465034485 0.0
0.4816264808177948 0.0
0.4816003739833832 0.0
0.48163720965385437 1.0
0.4816271662712097 0.0
0.48165634274482727 1.0
0.481675922870636 1.0
0.4816226065158844 0.0
0.48161962628364563 1.0
0.4816208481788635 1.0
0.48161619901657104 1.0
0.48163843154907227 0.0
0.4816005527973175 0.0
0.4816458523273468 1.0
0.4816405475139618 0.0
0.48165005445480347 0.0
0.4816133379936218 0.0
0.4816130995750427 0.0
0.4816359877586365 1.0
0.48160579800605774 0.0
0.4816073477268219 0.0
0.48163434863090515 1.0
0.4816373288631439 0.0
0.48162516951560974 0.0
0.48163628578186035 1.0
0.4816340208053589 0.0
0.48165038228034973 0.0
0.4816463887691498 0.0
0.4816383123397827 0.0
0.48166316747665405 1.0
0.48162904381752014 0.0
0.4816146492958069 0.0
TRAIN[steps=300] loss=0.686921 acc=0.594 P=0.000 R=0.000 F1=0.000000
DEV[steps=300] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48034629225730896 0.0
0.48034098744392395 0.0
0.4803493618965149 1.0
0.4803268015384674 1.0
0.48037174344062805 0.0
0.4803776443004608 0.0
0.48035305738449097 0.0
0.4803524911403656 0.0
0.4803396761417389 0.0
0.48035916686058044 1.0
0.4803524911403656 0.0
0.48035144805908203 1.0
0.4803358316421509 0.0
0.48034706711769104 0.0
0.4803508520126343 0.0
0.48034077882766724 0.0
0.48035189509391785 1.0
0.4803245961666107 1.0
0.4803577661514282 0.0
0.4803648889064789 0.0
0.4803355038166046 1.0
0.4803575575351715 1.0
0.4803743362426758 1.0
0.48033028841018677 0.0
0.4803708791732788 1.0
0.48034486174583435 1.0
0.4803520143032074 1.0
0.4803478717803955 0.0
0.48034629225730896 1.0
0.4803886413574219 0.0
0.4803479313850403 0.0
0.4803465008735657 1.0
0.48031988739967346 1.0
0.4803609251976013 1.0
0.480354905128479 0.0
0.4803359806537628 1.0
0.4803548753261566 1.0
0.4803629517555237 0.0
0.48035377264022827 0.0
0.4803656041622162 1.0
0.480337530374527 1.0
0.4803481996059418 1.0
0.4803510010242462 1.0
0.48034629225730896 1.0
0.48033010959625244 0.0
0.48038434982299805 0.0
0.480379194021225 0.0
0.48036906123161316 1.0
0.4803558588027954 1.0
0.48036202788352966 1.0
0.4803684949874878 1.0
0.4803682863712311 0.0
0.48032477498054504 1.0
0.48036959767341614 0.0
0.48036861419677734 1.0
0.48034045100212097 0.0
0.48037776350975037 0.0
0.48035144805908203 0.0
0.4803526699542999 1.0
0.4803386330604553 1.0
0.4803452789783478 0.0
0.48035579919815063 0.0
0.48035740852355957 0.0
0.48035508394241333 1.0
TRAIN[steps=400] loss=0.693925 acc=0.500 P=0.000 R=0.000 F1=0.000000
DEV[steps=400] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4827640652656555 0.0
0.48279646039009094 0.0
0.48276275396347046 0.0
0.4827660322189331 1.0
0.48277780413627625 0.0
0.48277729749679565 0.0
0.4827520251274109 1.0
0.4827621281147003 0.0
0.48277169466018677 0.0
0.482761025428772 0.0
0.4827407896518707 0.0
0.4827776849269867 0.0
0.4827735722064972 0.0
0.4827396869659424 1.0
0.482761412858963 1.0
0.4827728569507599 0.0
0.48277047276496887 1.0
0.482748419046402 0.0
0.4827766418457031 1.0
0.4827624559402466 0.0
0.48276445269584656 1.0
0.48276636004447937 1.0
0.4827461838722229 0.0
0.4827919602394104 0.0
0.4827772378921509 1.0
0.4827476143836975 0.0
0.4827791452407837 0.0
0.48275133967399597 0.0
0.48275890946388245 1.0
0.4827689230442047 1.0
0.48276764154434204 1.0
0.4827762544155121 0.0
0.4827961325645447 0.0
0.48281481862068176 0.0
0.48276519775390625 0.0
0.4827353358268738 1.0
0.4827510118484497 0.0
0.4827689230442047 0.0
0.48278263211250305 0.0
0.48275262117385864 0.0
0.4827706813812256 1.0
0.48273590207099915 0.0
0.4827767014503479 0.0
0.4827839136123657 1.0
0.4827532470226288 1.0
0.4827709197998047 0.0
0.48277562856674194 0.0
0.48276031017303467 1.0
0.4827651381492615 1.0
0.48274335265159607 1.0
0.4827699065208435 0.0
0.4827643632888794 0.0
0.4827808439731598 0.0
0.4827733039855957 0.0
0.4827648401260376 1.0
0.4827612340450287 0.0
0.48275691270828247 1.0
0.4827653467655182 0.0
0.48276662826538086 0.0
0.48277178406715393 0.0
0.4827575087547302 0.0
0.4827587902545929 0.0
0.48275691270828247 1.0
0.4827450215816498 1.0
TRAIN[steps=500] loss=0.684050 acc=0.641 P=0.000 R=0.000 F1=0.000000
DEV[steps=500] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4867643117904663 1.0
0.48678165674209595 1.0
0.4867839813232422 1.0
0.48677560687065125 0.0
0.48676997423171997 0.0
0.4867814779281616 0.0
0.4867771863937378 0.0
0.48676013946533203 0.0
0.486761212348938 0.0
0.48677363991737366 1.0
0.48678797483444214 0.0
0.4867858290672302 1.0
0.48676398396492004 1.0
0.48676159977912903 1.0
0.4867683947086334 1.0
0.4867515563964844 1.0
0.48675087094306946 1.0
0.4867905378341675 1.0
0.4867410361766815 1.0
0.48677119612693787 0.0
0.4867928922176361 0.0
0.4867953956127167 0.0
0.4867640733718872 1.0
0.48679599165916443 1.0
0.48676589131355286 0.0
0.48676595091819763 0.0
0.48673489689826965 0.0
0.48676860332489014 1.0
0.48677921295166016 0.0
0.4867783188819885 1.0
0.48676154017448425 0.0
0.48676520586013794 0.0
0.4867636263370514 0.0
0.4867827892303467 0.0
0.4867723286151886 1.0
0.48676127195358276 0.0
0.4867651164531708 0.0
0.4867917597293854 1.0
0.48675212264060974 0.0
0.48676690459251404 0.0
0.4867892861366272 0.0
0.4867846965789795 0.0
0.48678329586982727 1.0
0.48677363991737366 0.0
0.4867718815803528 0.0
0.48677515983581543 0.0
0.486777126789093 0.0
0.4867628514766693 1.0
0.4867906868457794 0.0
0.48680198192596436 0.0
0.48674634099006653 0.0
0.4867851138114929 1.0
0.48676949739456177 1.0
0.4867856204509735 1.0
0.48676833510398865 1.0
0.48678576946258545 1.0
0.48677176237106323 0.0
0.4867834746837616 0.0
0.4867836833000183 1.0
0.4867587685585022 0.0
0.48676714301109314 1.0
0.48676759004592896 1.0
0.48676374554634094 0.0
0.4867718815803528 1.0
TRAIN[steps=600] loss=0.691016 acc=0.547 P=0.000 R=0.000 F1=0.000000
DEV[steps=600] loss=0.010804 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48775115609169006 1.0
0.4877646565437317 0.0
0.4877839684486389 1.0
0.48775598406791687 0.0
0.48777738213539124 0.0
0.4877512753009796 0.0
0.48776841163635254 0.0
0.48775044083595276 1.0
0.48776915669441223 1.0
0.4877634644508362 0.0
0.4877440333366394 1.0
0.48777005076408386 1.0
0.48778215050697327 0.0
0.4877535402774811 1.0
0.4877537786960602 1.0
0.4877616763114929 0.0
0.48774468898773193 1.0
0.48774033784866333 1.0
0.48775479197502136 0.0
0.48777419328689575 1.0
0.48775923252105713 0.0
0.4877537786960602 1.0
0.4877578020095825 0.0
0.48775026202201843 1.0
0.48774123191833496 0.0
0.4877625107765198 1.0
0.48776113986968994 1.0
0.48775842785835266 0.0
0.48775407671928406 1.0
0.4877530336380005 1.0
0.4877510070800781 0.0
0.48775291442871094 1.0
0.4877488911151886 1.0
0.4877532124519348 1.0
0.4877653419971466 0.0
0.48774924874305725 1.0
0.4877554774284363 1.0
0.48774367570877075 1.0
0.48775991797447205 0.0
0.48777055740356445 0.0
0.48774027824401855 1.0
0.48775944113731384 1.0
0.4877592921257019 1.0
0.4877382516860962 0.0
0.4877418577671051 0.0
0.48775842785835266 0.0
0.48775333166122437 0.0
0.48774057626724243 0.0
0.4877646565437317 0.0
0.48774686455726624 1.0
0.48776760697364807 0.0
0.4877505898475647 1.0
0.4877537786960602 1.0
0.4877583086490631 0.0
0.4877628684043884 0.0
0.4877627491950989 1.0
0.4877505898475647 1.0
0.48773494362831116 1.0
0.4877622723579407 0.0
0.4877679646015167 0.0
0.48772531747817993 0.0
0.4877699315547943 1.0
0.4877849221229553 0.0
0.4877476394176483 0.0
TRAIN[steps=700] loss=0.694216 acc=0.484 P=0.000 R=0.000 F1=0.000000
DEV[steps=700] loss=0.010805 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4858127236366272 0.0
0.485844224691391 1.0
0.4858364164829254 0.0
0.4858202636241913 1.0
0.4858470559120178 1.0
0.48580896854400635 1.0
0.485843688249588 0.0
0.4858185648918152 0.0
0.48582836985588074 0.0
0.48581841588020325 0.0
0.4858534634113312 1.0
0.48582398891448975 0.0
0.4858124554157257 1.0
0.48582690954208374 1.0
0.48581767082214355 1.0
0.4858340620994568 0.0
0.4858309030532837 1.0
0.4858127236366272 1.0
0.48582762479782104 0.0
0.48585188388824463 0.0
0.4858074486255646 1.0
0.48581457138061523 1.0
0.4858279228210449 0.0
0.4858318567276001 0.0
0.4858361482620239 0.0
0.4858149290084839 0.0
0.4858338236808777 1.0
0.48584187030792236 0.0
0.48585623502731323 0.0
0.4858476221561432 0.0
0.48583984375 0.0
0.4858357310295105 0.0
0.4858105778694153 1.0
0.4858276844024658 0.0
0.485818475484848 1.0
0.4858146905899048 0.0
0.4858209490776062 1.0
0.485829621553421 0.0
0.48582494258880615 0.0
0.4858221709728241 0.0
0.4858234226703644 0.0
0.48581841588020325 1.0
0.4858148694038391 0.0
0.48581913113594055 1.0
0.4858234226703644 1.0
0.48583725094795227 0.0
0.48582711815834045 1.0
0.4858250021934509 1.0
0.48584020137786865 1.0
0.48582911491394043 1.0
0.4858503043651581 1.0
0.48582082986831665 1.0
0.4858432710170746 1.0
0.48583096265792847 1.0
0.4858308434486389 0.0
0.48583319783210754 0.0
0.48584166169166565 1.0
0.48583415150642395 1.0
0.48582151532173157 0.0
0.4858291447162628 1.0
0.4858488440513611 0.0
0.4858366847038269 1.0
0.4858478307723999 1.0
0.48582667112350464 1.0
TRAIN[steps=800] loss=0.694438 acc=0.484 P=0.000 R=0.000 F1=0.000000
DEV[steps=800] loss=0.010804 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48558515310287476 0.0
0.48563092947006226 0.0
0.4855964481830597 1.0
0.48560282588005066 1.0
0.4855765104293823 0.0
0.48560747504234314 1.0
0.48559942841529846 1.0
0.4855930209159851 0.0
0.4855976998806 0.0
0.4856031537055969 0.0
0.48559415340423584 0.0
0.4856014549732208 1.0
0.48561742901802063 1.0
0.4855886399745941 1.0
0.48559191823005676 0.0
0.4855855107307434 0.0
0.4856061339378357 1.0
0.4856126010417938 0.0
0.4856051802635193 0.0
0.485606849193573 1.0
0.48560404777526855 1.0
0.48559966683387756 0.0
0.48561564087867737 1.0
0.4856038987636566 0.0
0.4855935275554657 0.0
0.4856186807155609 0.0
0.4856117069721222 0.0
0.4855892062187195 0.0
0.4856031537055969 1.0
0.485596239566803 1.0
0.4856133759021759 0.0
0.48560574650764465 1.0
0.4856029152870178 0.0
0.4856085479259491 1.0
0.48559388518333435 0.0
0.4856027066707611 0.0
0.48560085892677307 0.0
0.48559054732322693 0.0
0.48561394214630127 0.0
0.4856029152870178 0.0
0.4856075942516327 1.0
0.4856027066707611 1.0
0.4855957329273224 1.0
0.4855779707431793 0.0
0.48559707403182983 1.0
0.48559844493865967 1.0
0.4855952858924866 1.0
0.48559892177581787 1.0
0.4856112599372864 1.0
0.4856119155883789 0.0
0.48559051752090454 1.0
0.48559921979904175 1.0
0.48559993505477905 0.0
0.485595166683197 0.0
0.48559629917144775 1.0
0.48560670018196106 1.0
0.4855855703353882 0.0
0.48560136556625366 0.0
0.4856001138687134 0.0
0.48560798168182373 1.0
0.48561400175094604 0.0
0.4856187701225281 0.0
0.48560842871665955 0.0
0.48561495542526245 1.0
TRAIN[steps=900] loss=0.690859 acc=0.547 P=0.000 R=0.000 F1=0.000000
DEV[steps=900] loss=0.010804 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4827043414115906 0.0
0.48271724581718445 1.0
0.4827128052711487 0.0
0.4827083349227905 0.0
0.4827187955379486 1.0
0.48272040486335754 0.0
0.48270219564437866 0.0
0.4827142357826233 0.0
0.4827192425727844 1.0
0.4826992452144623 1.0
0.4827117919921875 0.0
0.48271435499191284 0.0
0.48270830512046814 1.0
0.48270612955093384 1.0
0.48271724581718445 0.0
0.48271480202674866 1.0
0.4826967418193817 1.0
0.4827224612236023 1.0
0.482711523771286 1.0
0.48270195722579956 1.0
0.4827057421207428 1.0
0.4827134609222412 0.0
0.4827173352241516 0.0
0.4827181398868561 1.0
0.4827166795730591 0.0
0.48270413279533386 1.0
0.48271217942237854 0.0
0.48270612955093384 0.0
0.48269274830818176 1.0
0.48273035883903503 1.0
0.48271802067756653 0.0
0.48270750045776367 0.0
0.4827136695384979 0.0
0.4827178418636322 1.0
0.48271802067756653 1.0
0.482711523771286 0.0
0.4827161729335785 0.0
0.4826933443546295 0.0
0.48270222544670105 0.0
0.4827095568180084 1.0
0.4827030599117279 0.0
0.48271018266677856 0.0
0.48271846771240234 0.0
0.48270800709724426 1.0
0.4827153980731964 0.0
0.48269855976104736 0.0
0.4827013611793518 1.0
0.4827097952365875 0.0
0.4827103018760681 0.0
0.48270711302757263 0.0
0.48270517587661743 1.0
0.4826968014240265 0.0
0.48270711302757263 0.0
0.4827097952365875 1.0
0.4827265739440918 1.0
0.4827263355255127 0.0
0.48272189497947693 0.0
0.4827013611793518 0.0
0.482726514339447 1.0
0.48271533846855164 1.0
0.48271647095680237 1.0
0.4827101230621338 0.0
0.4827236235141754 0.0
0.4827154576778412 1.0
TRAIN[steps=1000] loss=0.689420 acc=0.562 P=0.000 R=0.000 F1=0.000000
DEV[steps=1000] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48331770300865173 1.0
0.48329809308052063 1.0
0.48330649733543396 0.0
0.4832932651042938 0.0
0.4833054542541504 0.0
0.4833082854747772 1.0
0.48332688212394714 0.0
0.4833047389984131 1.0
0.48330673575401306 1.0
0.4832979738712311 1.0
0.483316034078598 1.0
0.4833050072193146 0.0
0.48330891132354736 0.0
0.48330026865005493 0.0
0.4833095669746399 0.0
0.48329538106918335 0.0
0.4833170473575592 1.0
0.48330065608024597 1.0
0.4833098351955414 1.0
0.4832952618598938 0.0
0.48329681158065796 1.0
0.4833182096481323 1.0
0.4833104610443115 1.0
0.48330244421958923 0.0
0.4832952618598938 0.0
0.4833178222179413 0.0
0.48329994082450867 0.0
0.483302503824234 0.0
0.48331865668296814 0.0
0.48330044746398926 1.0
0.4833005368709564 0.0
0.48331719636917114 0.0
0.48330968618392944 1.0
0.48329660296440125 0.0
0.4833051860332489 1.0
0.48329514265060425 0.0
0.48331329226493835 1.0
0.4832928776741028 1.0
0.4833022654056549 0.0
0.48329687118530273 0.0
0.48329541087150574 0.0
0.48329848051071167 0.0
0.4833170473575592 0.0
0.48328790068626404 0.0
0.4832989275455475 0.0
0.4833057224750519 0.0
0.4833003878593445 1.0
0.4833157956600189 1.0
0.4832991659641266 1.0
0.48328474164009094 1.0
0.48330941796302795 0.0
0.4832960367202759 1.0
0.4833071231842041 1.0
0.48330584168434143 1.0
0.4833030104637146 1.0
0.4833013415336609 1.0
0.48330217599868774 0.0
0.4833255410194397 1.0
0.4833139181137085 0.0
0.48330265283584595 1.0
0.48330995440483093 1.0
0.4832959771156311 0.0
0.48331135511398315 0.0
0.48331207036972046 1.0
TRAIN[steps=1100] loss=0.692659 acc=0.516 P=0.000 R=0.000 F1=0.000000
DEV[steps=1100] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4833858907222748 1.0
0.483389288187027 1.0
0.48339128494262695 1.0
0.4833928346633911 1.0
0.4833835959434509 0.0
0.48339033126831055 0.0
0.4834039807319641 1.0
0.48337769508361816 0.0
0.48338937759399414 1.0
0.48339831829071045 0.0
0.4833986461162567 0.0
0.48339658975601196 1.0
0.4833809733390808 1.0
0.48339027166366577 1.0
0.4833890497684479 1.0
0.48339495062828064 0.0
0.4834015369415283 0.0
0.4834062159061432 0.0
0.48341378569602966 0.0
0.4833946228027344 1.0
0.4833930730819702 0.0
0.48338449001312256 0.0
0.4834038317203522 0.0
0.4833848774433136 0.0
0.48338961601257324 0.0
0.48339328169822693 1.0
0.4833974242210388 0.0
0.48339685797691345 0.0
0.48339352011680603 1.0
0.4833923876285553 1.0
0.4833899438381195 1.0
0.4833921790122986 0.0
0.4833928346633911 1.0
0.4833822548389435 1.0
0.48337969183921814 1.0
0.4833916127681732 1.0
0.48338738083839417 1.0
0.48339012265205383 0.0
0.4833866059780121 0.0
0.48338794708251953 1.0
0.48339781165122986 0.0
0.48338809609413147 0.0
0.48338988423347473 0.0
0.48339396715164185 0.0
0.48339101672172546 1.0
0.4834045469760895 1.0
0.48340192437171936 0.0
0.4833991825580597 0.0
0.483395516872406 0.0
0.48337623476982117 0.0
0.48338648676872253 0.0
0.4833870530128479 0.0
0.483399361371994 0.0
0.48339173197746277 0.0
0.48338693380355835 0.0
0.4833814203739166 0.0
0.48341110348701477 1.0
0.4833945035934448 0.0
0.4833816587924957 0.0
0.4833819270133972 1.0
0.48339903354644775 0.0
0.48338788747787476 0.0
0.48339229822158813 0.0
0.4833996295928955 0.0
TRAIN[steps=1200] loss=0.686432 acc=0.609 P=0.000 R=0.000 F1=0.000000
DEV[steps=1200] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4839992821216583 0.0
0.4840010106563568 1.0
0.48401734232902527 1.0
0.4839942753314972 1.0
0.48399069905281067 0.0
0.48398566246032715 1.0
0.48399218916893005 0.0
0.48400214314460754 1.0
0.48399874567985535 1.0
0.4839865565299988 1.0
0.48399829864501953 1.0
0.48399287462234497 1.0
0.48399075865745544 0.0
0.4839835464954376 1.0
0.4839855432510376 0.0
0.48400750756263733 0.0
0.48399001359939575 1.0
0.4839876890182495 1.0
0.48399198055267334 0.0
0.4839974641799927 1.0
0.4839886724948883 0.0
0.48400694131851196 0.0
0.48399436473846436 0.0
0.48399850726127625 0.0
0.48398956656455994 1.0
0.4839899241924286 0.0
0.48398444056510925 0.0
0.4839881360530853 0.0
0.4840036630630493 1.0
0.48399215936660767 0.0
0.48399001359939575 0.0
0.4839927554130554 1.0
0.48399120569229126 1.0
0.4839909076690674 0.0
0.48398643732070923 0.0
0.4839905798435211 0.0
0.48399391770362854 1.0
0.48400062322616577 0.0
0.4839995801448822 0.0
0.48400360345840454 0.0
0.4839901924133301 1.0
0.483993262052536 0.0
0.4839913547039032 1.0
0.4839779734611511 0.0
0.4839838743209839 0.0
0.4839983880519867 0.0
0.483996719121933 1.0
0.4840089976787567 1.0
0.4839933216571808 0.0
0.48398590087890625 0.0
0.48399868607521057 1.0
0.48397812247276306 1.0
0.4839918613433838 1.0
0.4839959442615509 0.0
0.4839816391468048 0.0
0.483996719121933 0.0
0.48398858308792114 1.0
0.48399001359939575 0.0
0.4839896857738495 0.0
0.48399773240089417 0.0
0.48398667573928833 0.0
0.4839938282966614 1.0
0.48398545384407043 1.0
0.4840027987957001 1.0
TRAIN[steps=1300] loss=0.690656 acc=0.547 P=0.000 R=0.000 F1=0.000000
DEV[steps=1300] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48285895586013794 1.0
0.4828568398952484 0.0
0.48285773396492004 1.0
0.4828680753707886 1.0
0.48285239934921265 1.0
0.4828689396381378 0.0
0.48287418484687805 0.0
0.48286062479019165 1.0
0.48286572098731995 0.0
0.4828594923019409 1.0
0.4828564524650574 1.0
0.4828575551509857 1.0
0.48285114765167236 1.0
0.4828564524650574 0.0
0.48286888003349304 0.0
0.48287302255630493 0.0
0.4828625023365021 1.0
0.4828605055809021 0.0
0.48287373781204224 0.0
0.4828517735004425 0.0
0.4828639030456543 1.0
0.482876181602478 1.0
0.4828598201274872 1.0
0.4828668236732483 0.0
0.4828638434410095 0.0
0.4828583896160126 1.0
0.48286885023117065 1.0
0.48287007212638855 0.0
0.4828627109527588 0.0
0.48286861181259155 1.0
0.48286083340644836 1.0
0.48284849524497986 0.0
0.4828660488128662 0.0
0.48286134004592896 0.0
0.4828549325466156 1.0
0.48286595940589905 0.0
0.4828653335571289 0.0
0.4828747808933258 1.0
0.48285484313964844 1.0
0.4828771650791168 0.0
0.48286449909210205 0.0
0.4828709661960602 0.0
0.482867568731308 0.0
0.48284193873405457 0.0
0.4828633964061737 0.0
0.48286527395248413 0.0
0.48286083340644836 1.0
0.48286643624305725 1.0
0.4828695058822632 0.0
0.4828508198261261 1.0
0.48286595940589905 1.0
0.4828600585460663 1.0
0.4828546643257141 1.0
0.4828566014766693 0.0
0.4828614890575409 0.0
0.48285773396492004 0.0
0.48286616802215576 1.0
0.48284637928009033 1.0
0.4828666150569916 1.0
0.4828672707080841 0.0
0.4828469455242157 1.0
0.48286938667297363 0.0
0.48287907242774963 1.0
0.482869952917099 0.0
TRAIN[steps=1400] loss=0.692667 acc=0.516 P=0.000 R=0.000 F1=0.000000
DEV[steps=1400] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4852214753627777 0.0
0.48522621393203735 0.0
0.48522502183914185 1.0
0.48521867394447327 0.0
0.4852210283279419 0.0
0.48522064089775085 0.0
0.48524242639541626 0.0
0.4852142930030823 0.0
0.4852309823036194 1.0
0.4852311313152313 0.0
0.4852357506752014 0.0
0.48522883653640747 0.0
0.4852304756641388 1.0
0.48521700501441956 0.0
0.485230416059494 0.0
0.4852135181427002 1.0
0.48521944880485535 1.0
0.48521319031715393 0.0
0.485230416059494 1.0
0.4852319359779358 0.0
0.4852260947227478 1.0
0.4852193593978882 1.0
0.4852309226989746 1.0
0.48523202538490295 0.0
0.48522597551345825 1.0
0.48521891236305237 0.0
0.4852367639541626 1.0
0.48521217703819275 0.0
0.48522236943244934 1.0
0.48522934317588806 0.0
0.4852258563041687 0.0
0.4852202534675598 0.0
0.4852219223976135 1.0
0.48522159457206726 0.0
0.485225647687912 1.0
0.48522236943244934 0.0
0.48522910475730896 0.0
0.485225647687912 1.0
0.48522812128067017 1.0
0.4852208197116852 1.0
0.4852304756641388 0.0
0.48520931601524353 0.0
0.48522764444351196 0.0
0.4852322041988373 1.0
0.4852302372455597 0.0
0.4852313697338104 0.0
0.485248863697052 0.0
0.4852205812931061 1.0
0.4852224886417389 1.0
0.4852205812931061 0.0
0.4852374196052551 0.0
0.4852351248264313 1.0
0.4852220416069031 0.0
0.485227108001709 0.0
0.4852297306060791 0.0
0.4852191209793091 0.0
0.48522210121154785 0.0
0.4852244555950165 0.0
0.48522427678108215 0.0
0.48522305488586426 1.0
0.4852273166179657 1.0
0.4852236807346344 1.0
0.48522037267684937 0.0
0.4852273762226105 0.0
TRAIN[steps=1500] loss=0.686194 acc=0.625 P=0.000 R=0.000 F1=0.000000
DEV[steps=1500] loss=0.010804 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.48031845688819885 1.0
0.4803064465522766 1.0
0.4803094267845154 1.0
0.4803085923194885 0.0
0.4803203046321869 1.0
0.48031678795814514 0.0
0.48031631112098694 1.0
0.48031067848205566 1.0
0.48031267523765564 0.0
0.4803139269351959 0.0
0.48031294345855713 0.0
0.4803139269351959 1.0
0.4803164601325989 1.0
0.4803060293197632 0.0
0.4803021550178528 1.0
0.4803062975406647 0.0
0.48030996322631836 1.0
0.4803164601325989 0.0
0.4803156554698944 1.0
0.48031091690063477 1.0
0.4803127348423004 1.0
0.48031461238861084 1.0
0.48032346367836 1.0
0.48031482100486755 0.0
0.48032528162002563 1.0
0.4803277552127838 1.0
0.4803128242492676 0.0
0.48030975461006165 1.0
0.4803203046321869 0.0
0.48032042384147644 0.0
0.4803217947483063 0.0
0.4803299009799957 1.0
0.48032042384147644 0.0
0.48031553626060486 0.0
0.48031124472618103 1.0
0.4803163707256317 1.0
0.48031318187713623 1.0
0.48029929399490356 1.0
0.4803204834461212 0.0
0.48030778765678406 1.0
0.48031744360923767 0.0
0.48031774163246155 0.0
0.48031488060951233 0.0
0.4803120791912079 1.0
0.48030635714530945 0.0
0.48031190037727356 0.0
0.4803181290626526 0.0
0.48031437397003174 1.0
0.48031318187713623 0.0
0.4803144931793213 0.0
0.4803117513656616 0.0
0.4803154766559601 0.0
0.48030370473861694 0.0
0.48031502962112427 1.0
0.48032626509666443 0.0
0.48031431436538696 1.0
0.4803094267845154 1.0
0.48032575845718384 0.0
0.4803144931793213 0.0
0.4803125560283661 1.0
0.48031216859817505 1.0
0.4803173542022705 0.0
0.4803124964237213 1.0
0.4803163707256317 0.0
TRAIN[steps=1600] loss=0.693924 acc=0.500 P=0.000 R=0.000 F1=0.000000
DEV[steps=1600] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4809128940105438 0.0
0.4809217154979706 0.0
0.4809146225452423 0.0
0.4809078276157379 1.0
0.48091354966163635 0.0
0.4809158146381378 0.0
0.48091399669647217 1.0
0.4809110760688782 0.0
0.4809076189994812 0.0
0.48090943694114685 0.0
0.4809187352657318 1.0
0.480913907289505 1.0
0.4809156060218811 1.0
0.48091113567352295 0.0
0.48092320561408997 0.0
0.4809183180332184 0.0
0.4809161126613617 0.0
0.48090860247612 1.0
0.48091834783554077 0.0
0.48091721534729004 0.0
0.480913907289505 1.0
0.48090386390686035 1.0
0.4809205234050751 0.0
0.48090749979019165 1.0
0.48090600967407227 0.0
0.48090988397598267 0.0
0.48091891407966614 0.0
0.4809121787548065 1.0
0.4809226095676422 1.0
0.4809189736843109 1.0
0.48092442750930786 1.0
0.48091021180152893 0.0
0.4809110164642334 0.0
0.4809128940105438 1.0
0.4809168577194214 1.0
0.48091378808021545 1.0
0.4809117019176483 1.0
0.48091500997543335 0.0
0.48091262578964233 0.0
0.4809165298938751 1.0
0.48092392086982727 0.0
0.4809189736843109 1.0
0.48090893030166626 1.0
0.480920672416687 1.0
0.48091962933540344 0.0
0.4809185266494751 1.0
0.4809153378009796 0.0
0.48091208934783936 1.0
0.4809158742427826 1.0
0.4809156656265259 0.0
0.48091113567352295 1.0
0.48091572523117065 0.0
0.4809141159057617 1.0
0.48092493414878845 1.0
0.48091575503349304 1.0
0.48091477155685425 0.0
0.48090803623199463 1.0
0.4809170961380005 0.0
0.48092755675315857 1.0
0.48092350363731384 0.0
0.48091429471969604 0.0
0.4809117019176483 1.0
0.4809183180332184 0.0
0.4809148907661438 0.0
TRAIN[steps=1700] loss=0.692683 acc=0.516 P=0.000 R=0.000 F1=0.000000
DEV[steps=1700] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4810085892677307 1.0
0.4810185730457306 0.0
0.4810241460800171 0.0
0.48101481795310974 1.0
0.4810231029987335 1.0
0.48101767897605896 0.0
0.4810143709182739 1.0
0.48101913928985596 0.0
0.48103657364845276 1.0
0.48101869225502014 1.0
0.4810295104980469 0.0
0.48101967573165894 0.0
0.48102089762687683 1.0
0.4810185730457306 0.0
0.4810256361961365 0.0
0.48102620244026184 0.0
0.4810177981853485 0.0
0.4810131788253784 1.0
0.4810258150100708 0.0
0.48101669549942017 1.0
0.48101553320884705 0.0
0.4810200035572052 0.0
0.481019526720047 0.0
0.48101985454559326 1.0
0.4810192286968231 1.0
0.4810244143009186 1.0
0.4810253083705902 1.0
0.48101532459259033 1.0
0.4810182452201843 0.0
0.48101726174354553 1.0
0.48102396726608276 1.0
0.48102685809135437 1.0
0.48101767897605896 0.0
0.48102596402168274 0.0
0.48102912306785583 1.0
0.4810183644294739 1.0
0.48101845383644104 1.0
0.48102596402168274 0.0
0.48102396726608276 1.0
0.48101913928985596 1.0
0.4810176491737366 0.0
0.4810212254524231 0.0
0.48101648688316345 0.0
0.48101991415023804 0.0
0.48102349042892456 0.0
0.4810234308242798 0.0
0.48102137446403503 0.0
0.48102498054504395 0.0
0.48102137446403503 0.0
0.4810248613357544 1.0
0.48101806640625 1.0
0.4810260832309723 0.0
0.48101675510406494 0.0
0.4810274541378021 0.0
0.4810348451137543 1.0
0.4810210168361664 0.0
0.48102784156799316 1.0
0.481017142534256 0.0
0.4810207188129425 1.0
0.48101475834846497 0.0
0.4810221493244171 0.0
0.48102056980133057 0.0
0.4810273051261902 1.0
0.4810221195220947 0.0
TRAIN[steps=1800] loss=0.689121 acc=0.562 P=0.000 R=0.000 F1=0.000000
DEV[steps=1800] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4844318628311157 1.0
0.4844467341899872 1.0
0.4844405949115753 1.0
0.4844397008419037 0.0
0.48443615436553955 1.0
0.48444247245788574 0.0
0.4844401776790619 0.0
0.4844450056552887 0.0
0.48444393277168274 1.0
0.48443520069122314 1.0
0.4844363331794739 0.0
0.4844423234462738 1.0
0.48443105816841125 0.0
0.48444417119026184 0.0
0.4844387471675873 1.0
0.4844386875629425 0.0
0.48444315791130066 0.0
0.4844367802143097 0.0
0.48444411158561707 0.0
0.48442962765693665 1.0
0.4844481945037842 1.0
0.4844438135623932 0.0
0.48444652557373047 1.0
0.4844372868537903 1.0
0.48443856835365295 1.0
0.4844423830509186 1.0
0.48443832993507385 1.0
0.484443724155426 1.0
0.4844399094581604 0.0
0.48444506525993347 1.0
0.48443877696990967 1.0
0.48443353176116943 0.0
0.48443442583084106 0.0
0.48445335030555725 1.0
0.4844394028186798 1.0
0.48443958163261414 1.0
0.4844321310520172 1.0
0.48443812131881714 0.0
0.4844377934932709 1.0
0.4844438135623932 1.0
0.48444247245788574 1.0
0.4844437837600708 0.0
0.4844398498535156 0.0
0.48444169759750366 1.0
0.4844341576099396 0.0
0.4844495356082916 0.0
0.4844455122947693 1.0
0.48444750905036926 1.0
0.4844447374343872 0.0
0.4844443202018738 0.0
0.4844495356082916 1.0
0.4844447374343872 1.0
0.48443958163261414 0.0
0.4844430983066559 0.0
0.484435498714447 0.0
0.48444220423698425 0.0
0.48444926738739014 1.0
0.4844339191913605 0.0
0.4844316244125366 1.0
0.4844461679458618 1.0
0.48444271087646484 0.0
0.48444125056266785 0.0
0.4844297170639038 0.0
0.48443493247032166 0.0
TRAIN[steps=1900] loss=0.694603 acc=0.484 P=0.000 R=0.000 F1=0.000000
DEV[steps=1900] loss=0.010804 acc=0.519 P=0.000 R=0.000 F1=0.000000
model sim and label tuples:
0.4829319417476654 0.0
0.4829254448413849 0.0
0.48293009400367737 1.0
0.48293137550354004 0.0
0.4829287827014923 1.0
0.48292720317840576 0.0
0.48292553424835205 1.0
0.4829224944114685 0.0
0.48293182253837585 1.0
0.48292842507362366 1.0
0.4829302728176117 1.0
0.48292019963264465 1.0
0.4829353392124176 1.0
0.4829300045967102 0.0
0.48292598128318787 0.0
0.48292943835258484 1.0
0.48292115330696106 1.0
0.48292943835258484 0.0
0.48292967677116394 0.0
0.48292431235313416 1.0
0.48292386531829834 0.0
0.48292720317840576 0.0
0.48292672634124756 1.0
0.48292475938796997 1.0
0.4829236567020416 0.0
0.4829261004924774 0.0
0.48293423652648926 0.0
0.4829236567020416 1.0
0.4829291105270386 1.0
0.482936292886734 0.0
0.48292988538742065 1.0
0.48293232917785645 0.0
0.4829261004924774 1.0
0.4829292297363281 1.0
0.4829319417476654 1.0
0.4829293191432953 1.0
0.4829258918762207 1.0
0.4829348921775818 0.0
0.4829217791557312 1.0
0.4829273223876953 0.0
0.48292070627212524 0.0
0.4829266667366028 1.0
0.4829268753528595 1.0
0.48293188214302063 0.0
0.48292744159698486 0.0
0.4829252064228058 0.0
0.48293423652648926 1.0
0.4829232096672058 1.0
0.4829292595386505 0.0
0.4829323887825012 1.0
0.48293009400367737 0.0
0.48292276263237 0.0
0.4829246997833252 0.0
0.4829263687133789 1.0
0.48292216658592224 1.0
0.48292627930641174 0.0
0.48292264342308044 1.0
0.4829254448413849 0.0
0.4829285442829132 1.0
0.482930988073349 1.0
0.48292821645736694 0.0
0.4829215407371521 0.0
0.48292550444602966 0.0
0.48292967677116394 0.0
TRAIN[steps=2000] loss=0.693731 acc=0.500 P=0.000 R=0.000 F1=0.000000
DEV[steps=2000] loss=0.010803 acc=0.519 P=0.000 R=0.000 F1=0.000000
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0
No improvement for a long time, early-stopping at best F1=0.0